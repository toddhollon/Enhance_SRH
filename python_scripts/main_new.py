'''
Ideas for paper
1) Random noise generation
2) Empirical noise generator
    a) generated by tisse type
    b) across the entire dataset
    c) Local noise generator

Ideas:
RANDOM NOISE GENERATION
Perceptual metrics

'''

import numpy as np
from keras.layers import Input, Dense
from keras.models import Model, load_model
from keras.optimizers import Adam
from keras.metrics import mae
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras import backend as K
import matplotlib.pyplot as plt
from model import unet
from imageio import imread
from skimage.transform import resize
from skimage.measure import compare_psnr, compare_ssim


def nio_preprocessing_function(image):
    """
    Channel-wise means calculated over NIO dataset
    """
    image[:,:,0] -= 20.0
    image[:,:,1] -= 85.1
    image[:,:,2] -= 94.17
    image = image.clip(min = -127, max = 127)
    return image

def reverse_preprocessing_function(image):
    image[:,:,0] += 20.0
    image[:,:,1] += 85.1
    image[:,:,2] += 94.17
    image = image.clip(min = 0, max = 255)
    return image.astype(np.uint8)

def return_channels(array):
    """
    Helper function to return channels
    """
    return array[:,:,0], array[:,:,1], array[:,:,2]

def min_max_rescaling(array, percentile_clip = 3):
    p_low, p_high = np.percentile(array, (percentile_clip, 100 - percentile_clip))
    array = array.clip(min = p_low, max = p_high)
    img = (array - p_low)/(p_high - p_low)
    return img

def channel_rescaling(array):
    DNA, CH2, CH3 = return_channels(array.astype('float'))
    img = np.empty((array.shape[0], array.shape[1], 3), dtype='float')

    img[:,:,0] = min_max_rescaling(DNA)
    img[:,:,1] = min_max_rescaling(CH2)
    img[:,:,2] = min_max_rescaling(CH3)

    img *= 255
    
    return img.astype(np.uint8)

def rescale(img):
    rescaled_image = (img - img.min())/(img.max() - img.min()) * 255
    return rescaled_image.astype(np.uint8)

def uniform_noise_generator(batch, sigma = 100):
    # return image parameters
    batch_size, height, width, channels = batch.shape[0], batch.shape[1], batch.shape[2], batch.shape[3]

    # generate random uniform noise
    noise = np.random.random_sample(size=(batch_size, height, width, channels))

    batch = batch + (noise * sigma)   
    # batch = batch.clip(min=-127, max=127)    

    return batch

def gaussian_noise_generator(batch, sigma_range = (25,150)):
    # return image parameters
    batch_size, height, width, channels = batch.shape[0], batch.shape[1], batch.shape[2], batch.shape[3]

    # generate random uniform noise
    sigma = np.random.randint(low = sigma_range[0], high = sigma_range[1])
    noise = np.random.normal(loc=0.0, scale=sigma, size=(batch_size, height, width, channels))

    return batch + noise

def denoising_generator(generator, noise_function = gaussian_noise_generator):
    for batch in generator:
        noisy_batch = noise_function(batch)
        yield noisy_batch, batch

def psnr_mae(image1, image2):
    error = np.abs(np.mean(np.subtract(image1.astype(float), image2.astype(float))))
    psnr = 10 * np.log10(255/error)
    return psnr

def plotting_function_inference(img, noisy_img, pred_img):

    fig = plt.figure()
    ax1 = fig.add_subplot(1,3,1)
    ax1.imshow(img)
    ax1.set_title("Full resolution image")

    ax2 = fig.add_subplot(1,3,2)
    ax2.imshow(noisy_img)
    ax2.set_title("Noisy image: PSNR = " + str(np.round(psnr_mae(img, noisy_img), decimals = 3)) + " SSIM = " + str(np.round(compare_ssim(img, noisy_img, multichannel=True), decimals=3)))

    ax3 = fig.add_subplot(1,3,3)
    ax3.imshow(pred_img)
    ax3.set_title("UNet prediction: PSNR = " + str(np.round(psnr_mae(img, pred_img), decimals = 3)) + " SSIM = " + str(np.round(compare_ssim(img, pred_img, multichannel=True), decimals=3)))

    plt.suptitle("Enhancing stimulated Raman histology")
    plt.show()

def iterate_generator(generator, model):

    img_stack = next(validation_generator)
    noisy_img_stack = gaussian_noise_generator(img_stack, sigma_range=(50, 51))
    decod_img_stack = model.predict(noisy_img_stack)
    
    img = reverse_preprocessing_function(img_stack[0,:,:,:])
    noisy_img = reverse_preprocessing_function(noisy_img_stack[0,:,:,:])
    decod_img = reverse_preprocessing_function(decod_img_stack[0,:,:,:])
    plotting_function_inference(img, noisy_img, decod_img)

def denoise_image(image_path, model, noise_type = gaussian_noise_generator, sigma = 50):
    
    height = model.input_shape[1]
    
    image = imread(image_path).astype(float)
    image = resize(image, output_shape=(height, height))
    image = nio_preprocessing_function(image)

    image = image[None,:,:,:]
    noisy_image = gaussian_noise_generator(image, sigma_range=(sigma, sigma + 1))
    decod_image = model.predict(noisy_image)

    image = reverse_preprocessing_function(image[0,:,:,:])
    noisy_image = reverse_preprocessing_function(noisy_image[0,:,:,:])
    decod_image = reverse_preprocessing_function(decod_image[0,:,:,:])
    plotting_function_inference(image, noisy_image, decod_image)

    


# input_img = Input(shape=(HEIGHT, WIDTH, CHANNELS))
# x = Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)
# x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
# decoded = Conv2D(3, (3, 3), activation='linear', padding='same')(x)
# denoiser = Model(input_img, decoded)
# denoiser.compile(optimizer = Adam(lr = 0.001), loss = 'mean_absolute_error', metrics = ['mae'])



if __name__ == "__main__":
    
    training_directory = "/home/todd/Desktop/SRH_genetics/srh_patches/patches/training_patches/training"
    validation_directory = "/home/todd/Desktop/SRH_genetics/srh_patches/patches/training_patches/validation"

    HEIGHT, WIDTH, CHANNELS = 256, 256, 3
    BATCH_SIZE = 20

    unet = load_model("/home/todd/Desktop/Unet_denoiser.hdf5")

    # Define the generator
    train_generator = ImageDataGenerator(
        horizontal_flip=True,
        vertical_flip=True,
        preprocessing_function = nio_preprocessing_function,
        data_format = "channels_last").flow_from_directory(directory = training_directory, 
        target_size = (HEIGHT, WIDTH), interpolation = "bicubic", color_mode = 'rgb', classes = None, class_mode = None, 
        batch_size = BATCH_SIZE, shuffle = True)
        # save_to_dir = "/home/todd/Desktop/test_dir/keras_save_dir")

    validation_generator = ImageDataGenerator(
        horizontal_flip=True,
        vertical_flip=True,
        preprocessing_function = nio_preprocessing_function,
        data_format = "channels_last").flow_from_directory(directory = validation_directory, 
        target_size = (HEIGHT, WIDTH), interpolation = "bicubic", color_mode = 'rgb', classes = None, class_mode = None, 
        batch_size = BATCH_SIZE, shuffle = True)
    
    
    Unet = unet(input_size = (512, 512, 3))

    Unet = unet(input_size = (HEIGHT, WIDTH, CHANNELS))
    adam = Adam(lr=0.00005)
    unet.compile(optimizer=adam, loss='mean_absolute_error', metrics=['mae'])

    unet.fit_generator(denoising_generator(train_generator),
                    epochs=30,
                    steps_per_epoch=1500,
                    shuffle=True)


    iterate_generator(generator=validation_generator, model = unet)
    denoise_image(image_path="/home/todd/Desktop/SRH_genetics/srh_patches/patches/IDHmut_1p19qnormal/NIO472_1_414.tif", model = unet, sigma=100)



